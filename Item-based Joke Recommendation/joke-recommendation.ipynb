{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d01f4eed",
   "metadata": {},
   "source": [
    "# Item-Based Joke Recommendation Project\n",
    "\n",
    "This notebook explores collaborative filtering techniques for recommending jokes to users. It walks through data preparation, exploratory analyses, model development, and evaluation steps for both baseline and enhanced recommenders.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad49f68b-1c88-4335-a16d-5de14f4865ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itemBasedRec import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8c587b-031a-4a2f-8f8a-92819782f036",
   "metadata": {},
   "source": [
    "## Dataset and Resources\n",
    "\n",
    "This project revisits the item-based recommender algorithm from _Machine Learning in Action_ and adapts it to the Jester Online Joke Recommender System. The modified implementation in `itemBasedRec.py` supports several extensions explored throughout the notebook. The data include two files:\n",
    "\n",
    "- `modified_jester_data.csv`: ratings for 100 jokes by 1,000 users on a normalized 1–21 scale (zeros indicate missing ratings).\n",
    "- `jokes.csv`: textual descriptions associated with each joke identifier.\n",
    "\n",
    "The following sections walk through data ingestion, baseline recommendations, similarity exploration, model-based enhancements, and evaluation workflows.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d75da8-84a4-419c-b12d-3699c28a317c",
   "metadata": {},
   "source": [
    "### Baseline Recommendation Setup\n",
    "\n",
    "Load the joke metadata and rating matrix, then use the existing `recommend` function to generate top-5 suggestions. Compare how Pearson and cosine similarities drive recommendations for user 117 with the standard estimator. For user 441, contrast the standard estimator with the SVD-based variant (both using Pearson similarity) to see how latent representations change the outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a0d4918-2d6d-49ad-bd9c-335108f08a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A man visits the doctor. The doctor says \"I have bad news for you.You have cancer and Alzheimer\\'s disease\". The man replies \"Well thank God I don\\'t have cancer!\"'\n",
      " 'This couple had an excellent relationship going until one day he came home from work to find his girlfriend packing. He asked her why she was leaving him and she told him that she had heard awful things about him. \"What could they possibly have said to make you move out?\" \"They told me that you were a pedophile.\" He replied \"That\\'s an awfully big word for a ten year old.\"'\n",
      " \"Q. What's 200 feet long and has 4 teeth? A. The front row at a Willie Nelson Concert.\"\n",
      " \"Q. What's the difference between a man and a toilet? A. A toilet doesn't follow you around after you use it.\"\n",
      " \"Q. What's O. J. Simpson's Internet address? A.\\tSlash slash backslash slash slash escape.\"]\n"
     ]
    }
   ],
   "source": [
    "# jokes_df = pd.read_csv('jokes/jokes.csv', header=None, index_col=0)\n",
    "# jokes_df.head(5)\n",
    "\n",
    "jokes = load_jokes(\"jokes/jokes.csv\")\n",
    "print(jokes[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e60569d-0f8b-4534-bede-1624c5f5346f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.18</td>\n",
       "      <td>19.79</td>\n",
       "      <td>1.34</td>\n",
       "      <td>2.84</td>\n",
       "      <td>3.48</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.15</td>\n",
       "      <td>15.17</td>\n",
       "      <td>2.02</td>\n",
       "      <td>6.24</td>\n",
       "      <td>...</td>\n",
       "      <td>13.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.08</td>\n",
       "      <td>10.71</td>\n",
       "      <td>17.36</td>\n",
       "      <td>15.37</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.34</td>\n",
       "      <td>10.27</td>\n",
       "      <td>5.66</td>\n",
       "      <td>19.88</td>\n",
       "      <td>20.22</td>\n",
       "      <td>...</td>\n",
       "      <td>13.82</td>\n",
       "      <td>6.05</td>\n",
       "      <td>10.71</td>\n",
       "      <td>18.86</td>\n",
       "      <td>10.81</td>\n",
       "      <td>8.86</td>\n",
       "      <td>14.06</td>\n",
       "      <td>11.34</td>\n",
       "      <td>6.68</td>\n",
       "      <td>12.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.03</td>\n",
       "      <td>20.27</td>\n",
       "      <td>20.03</td>\n",
       "      <td>20.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>19.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.80</td>\n",
       "      <td>19.16</td>\n",
       "      <td>8.18</td>\n",
       "      <td>17.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>11.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19.50</td>\n",
       "      <td>15.61</td>\n",
       "      <td>6.83</td>\n",
       "      <td>5.61</td>\n",
       "      <td>12.36</td>\n",
       "      <td>12.60</td>\n",
       "      <td>18.04</td>\n",
       "      <td>15.61</td>\n",
       "      <td>10.56</td>\n",
       "      <td>16.73</td>\n",
       "      <td>...</td>\n",
       "      <td>16.19</td>\n",
       "      <td>16.58</td>\n",
       "      <td>15.27</td>\n",
       "      <td>16.19</td>\n",
       "      <td>16.73</td>\n",
       "      <td>12.55</td>\n",
       "      <td>14.11</td>\n",
       "      <td>17.55</td>\n",
       "      <td>12.80</td>\n",
       "      <td>12.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0      1      2      3      4      5      6      7      8      9   ...  \\\n",
       "0   3.18  19.79   1.34   2.84   3.48   2.50   1.15  15.17   2.02   6.24  ...   \n",
       "1  15.08  10.71  17.36  15.37   8.62   1.34  10.27   5.66  19.88  20.22  ...   \n",
       "2   0.00   0.00   0.00   0.00  20.03  20.27  20.03  20.27   0.00   0.00  ...   \n",
       "3   0.00  19.35   0.00   0.00  12.80  19.16   8.18  17.21   0.00  12.84  ...   \n",
       "4  19.50  15.61   6.83   5.61  12.36  12.60  18.04  15.61  10.56  16.73  ...   \n",
       "\n",
       "      90     91     92     93     94     95     96     97     98     99  \n",
       "0  13.82   0.00   0.00   0.00   0.00   0.00   5.37   0.00   0.00   0.00  \n",
       "1  13.82   6.05  10.71  18.86  10.81   8.86  14.06  11.34   6.68  12.07  \n",
       "2   0.00   0.00   0.00  20.08   0.00   0.00   0.00   0.00   0.00   0.00  \n",
       "3   0.00   0.00   0.00  11.53   0.00   0.00   0.00   0.00   0.00   0.00  \n",
       "4  16.19  16.58  15.27  16.19  16.73  12.55  14.11  17.55  12.80  12.60  \n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jester_data_df = pd.read_csv(\"jokes/modified_jester_data.csv\", header=None)\n",
    "jester_data_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d9b6a3-4650-44b3-895b-e2fe496ef04c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.18, 19.79,  1.34, ...,  0.  ,  0.  ,  0.  ],\n",
       "       [15.08, 10.71, 17.36, ..., 11.34,  6.68, 12.07],\n",
       "       [ 0.  ,  0.  ,  0.  , ...,  0.  ,  0.  ,  0.  ],\n",
       "       ...,\n",
       "       [16.58, 16.63, 15.85, ...,  0.  ,  0.  ,  0.  ],\n",
       "       [ 3.67,  4.45,  3.67, ...,  3.77,  3.77,  3.28],\n",
       "       [ 9.88, 11.73,  9.16, ...,  0.  ,  0.  ,  0.  ]], shape=(1000, 100))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jester_data_np = jester_data_df.to_numpy()\n",
    "jester_data_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67ce4f57-2506-48aa-a180-0eee4668dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation_output(recommend, jokes=jokes):\n",
    "    for id, score in recommend:\n",
    "        print(f\"Joke ID: {id}\")\n",
    "        print(f\"Score: {score}\")\n",
    "        print(f\"Joke Text: {get_joke_text(jokes, id)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f66fa1bc-9b6c-424b-9e77-19d844405dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke ID: 97\n",
      "Score: 10.611085062642834\n",
      "Joke Text: Age and Womanhood1. Between the ages of 13 and 18 ... She is like Africa virgin and unexplored. 2. Between the ages of 19 and 35 ... She is like Asia hot and exotic. 3. Between the ages of 36 and 45 ... She is like America fully explored breathtakingly beautiful and free with her resources.4. Between the ages of 46 and 56 ...She is like Europe exhausted but still has points of interest. 5. After 56 she is like Australia ...Everybody knows it's down there but who gives a damn?\n",
      "\n",
      "Joke ID: 99\n",
      "Score: 10.60795594948322\n",
      "Joke Text: Q: What's the difference between greeting a Queen and greeting thePresident of the United  States?A: You only have to get on one knee to greet the queen.\n",
      "\n",
      "Joke ID: 92\n",
      "Score: 10.59028160354093\n",
      "Joke Text: Reaching the end of a job interview the human resources person asked a young engineer fresh out of Stanford\"And what starting salary were you looking for?\"The engineer said \"In the neighborhood of $125000 a year depending on the benefits package.\"The interviewer said \"Well what would you say to a package of 5-weeks vacation 14 paid holidays full medical and dental company matching retirement fund to 50% of salary and a company car leased every 2 years - say a red Corvette?\"The Engineer sat up straight and said \"Wow! Are you kidding?\"And the interviewer replied \"Yeah but you started it.\"\n",
      "\n",
      "Joke ID: 75\n",
      "Score: 10.573787944861072\n",
      "Joke Text: There once was a man and a woman that both  got in  a terrible car wreck. Both of their vehicles  were completely destroyed buy fortunately no one  was   hurt.  In thankfulness the woman said to the man 'We are both okay so we should celebrate. I have   a  bottle of wine in my car let's open it.' So the woman got the bottle out of the car and  handed it to the man. The man took a really big drink and handed the woman the bottle. The  woman  closed the bottle and put it down. The man  asked  'Aren't you going to take a drink?' The woman cleverly replied 'No I think I'll  just  wait for the cops to get here.'\n",
      "\n",
      "Joke ID: 80\n",
      "Score: 10.571721714773872\n",
      "Joke Text: An Asian man goes into a New York CityBank to exchange 10000 yen forAmerican Currency.  The teller gives him $72.00.  The next month theAsian man goes into the same bank with 10000 yen and receives $62.00.He asks \"How come? Only $62.00?\" The teller says \"Fluctuations-Fluctuations!\"Whereupon the Asian man looks back at the teller and says \"Fluk youAmelicans too!\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pearson_recommend = recommend(\n",
    "    dataMat=jester_data_np, user=117, N=5, simMeas=pearsonSim, estMethod=standEst\n",
    ")\n",
    "recommendation_output(pearson_recommend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dde5da5-e678-4e6d-af8a-3edc53e47b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke ID: 97\n",
      "Score: 10.568879679136282\n",
      "Joke Text: Age and Womanhood1. Between the ages of 13 and 18 ... She is like Africa virgin and unexplored. 2. Between the ages of 19 and 35 ... She is like Asia hot and exotic. 3. Between the ages of 36 and 45 ... She is like America fully explored breathtakingly beautiful and free with her resources.4. Between the ages of 46 and 56 ...She is like Europe exhausted but still has points of interest. 5. After 56 she is like Australia ...Everybody knows it's down there but who gives a damn?\n",
      "\n",
      "Joke ID: 99\n",
      "Score: 10.566963805972222\n",
      "Joke Text: Q: What's the difference between greeting a Queen and greeting thePresident of the United  States?A: You only have to get on one knee to greet the queen.\n",
      "\n",
      "Joke ID: 92\n",
      "Score: 10.56570515577353\n",
      "Joke Text: Reaching the end of a job interview the human resources person asked a young engineer fresh out of Stanford\"And what starting salary were you looking for?\"The engineer said \"In the neighborhood of $125000 a year depending on the benefits package.\"The interviewer said \"Well what would you say to a package of 5-weeks vacation 14 paid holidays full medical and dental company matching retirement fund to 50% of salary and a company car leased every 2 years - say a red Corvette?\"The Engineer sat up straight and said \"Wow! Are you kidding?\"And the interviewer replied \"Yeah but you started it.\"\n",
      "\n",
      "Joke ID: 88\n",
      "Score: 10.565431359820924\n",
      "Joke Text: A radio conversation of a US naval ship with Canadian authorities ... Americans: Please divert your course 15 degrees to the North to avoid a collision.Canadians: Recommend you divert YOUR course 15 degrees to the South to avoid a collision.Americans: This is the Captain of a US Navy ship.  I say again divert YOUR course.Canadians: No.  I say again you divert YOUR course.Americans: This is the aircraft carrier USS LINCOLN the second largest ship in the United States' Atlantic Fleet. We are accompanied by three destroyers three cruisers and numerous support vessels. I demand that you change your course 15 degrees north that's ONE FIVE DEGREES NORTH or counter-measures will be undertaken to ensure the safety of this ship.Canadians: This is a lighthouse.  Your call.\n",
      "\n",
      "Joke ID: 75\n",
      "Score: 10.564995264885125\n",
      "Joke Text: There once was a man and a woman that both  got in  a terrible car wreck. Both of their vehicles  were completely destroyed buy fortunately no one  was   hurt.  In thankfulness the woman said to the man 'We are both okay so we should celebrate. I have   a  bottle of wine in my car let's open it.' So the woman got the bottle out of the car and  handed it to the man. The man took a really big drink and handed the woman the bottle. The  woman  closed the bottle and put it down. The man  asked  'Aren't you going to take a drink?' The woman cleverly replied 'No I think I'll  just  wait for the cops to get here.'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cosine_recommend = recommend(\n",
    "    dataMat=jester_data_np, user=117, N=5, simMeas=cosineSim, estMethod=standEst\n",
    ")\n",
    "recommendation_output(cosine_recommend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4fa9cbf-0744-4e08-9f2e-ca0a33aafd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke ID: 79\n",
      "Score: 13.971888175175714\n",
      "Joke Text: Hillary Bill Clinton and the Pope are sitting together on an airplane. Bill says \"I could throw one thousand dollar bill out of this plane and make one person very happy.\"Hillary says \"I could throw 10 hundred dollar bills out of the plane and make 10 people very happy.\"The Pope chips in and says \"I could throw Bill out of the airplane and make the whole country happy.\"\n",
      "\n",
      "Joke ID: 5\n",
      "Score: 13.965840113937233\n",
      "Joke Text: Bill & Hillary are on a trip back to Arkansas. They're almost out of gas so Bill pulls into a service station on the outskirts of town. The attendant runs out of the station to serve them when Hillary realizes it's an old boyfriend from high school. She and the attendant chat as he gases up their car and cleans the windows. Then they all say good-bye. As Bill pulls the car onto the road he turns to Hillary and says 'Now aren't you glad you married me and not him ? You could've been the wife of a grease monkey !' To which Hillary replied 'No Bill. If I would have married him you'd be pumping gas and he would be the President !'\n",
      "\n",
      "Joke ID: 71\n",
      "Score: 13.960180088350794\n",
      "Joke Text: On the first day of college the Dean addressed the students pointing out some of the rules:\"The female dormitory will be out-of-bounds for all male students and the male dormitory to the female students. Anybody caught breaking this rule will be fined $20 the first time.\" He continued \"Anybody caught breaking this rule the second time will be fined $60. Being caught a third time will cost you a fine of $180. Are there any questions ?\"At this point a male student in the crowd inquired:\"How much for a season pass ?\"\n",
      "\n",
      "Joke ID: 99\n",
      "Score: 13.952483912473475\n",
      "Joke Text: Q: What's the difference between greeting a Queen and greeting thePresident of the United  States?A: You only have to get on one knee to greet the queen.\n",
      "\n",
      "Joke ID: 88\n",
      "Score: 13.911394434320092\n",
      "Joke Text: A radio conversation of a US naval ship with Canadian authorities ... Americans: Please divert your course 15 degrees to the North to avoid a collision.Canadians: Recommend you divert YOUR course 15 degrees to the South to avoid a collision.Americans: This is the Captain of a US Navy ship.  I say again divert YOUR course.Canadians: No.  I say again you divert YOUR course.Americans: This is the aircraft carrier USS LINCOLN the second largest ship in the United States' Atlantic Fleet. We are accompanied by three destroyers three cruisers and numerous support vessels. I demand that you change your course 15 degrees north that's ONE FIVE DEGREES NORTH or counter-measures will be undertaken to ensure the safety of this ship.Canadians: This is a lighthouse.  Your call.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for user with id 441 only with Pearson similarity using both the standard estimator\n",
    "standEst_pearson_recommend = recommend(\n",
    "    dataMat=jester_data_np, user=441, N=5, simMeas=pearsonSim, estMethod=standEst\n",
    ")\n",
    "recommendation_output(standEst_pearson_recommend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45bceac5-2704-487f-95d0-2de0d5c5dbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joke ID: 45\n",
      "Score: 14.299797597297259\n",
      "Joke Text: A couple has been married for 75 years. For the husband's 95thbirthday his wife decides to surprise him by hiring a prostitute.That day the doorbell rings. The husband uses his walker to get to the door and opens it. A 21-year-old in a latex outfit smiles and says \"Hi I here to give you super sex!\" The old man says \"I'll take the soup.\"\n",
      "\n",
      "Joke ID: 5\n",
      "Score: 14.225833193529487\n",
      "Joke Text: Bill & Hillary are on a trip back to Arkansas. They're almost out of gas so Bill pulls into a service station on the outskirts of town. The attendant runs out of the station to serve them when Hillary realizes it's an old boyfriend from high school. She and the attendant chat as he gases up their car and cleans the windows. Then they all say good-bye. As Bill pulls the car onto the road he turns to Hillary and says 'Now aren't you glad you married me and not him ? You could've been the wife of a grease monkey !' To which Hillary replied 'No Bill. If I would have married him you'd be pumping gas and he would be the President !'\n",
      "\n",
      "Joke ID: 10\n",
      "Score: 14.138533302504912\n",
      "Joke Text: Q. What do a hurricane a tornado and a redneck divorce all have in common? A. Someone's going to lose their trailer...\n",
      "\n",
      "Joke ID: 50\n",
      "Score: 14.136345754056169\n",
      "Joke Text: Did you hear that Clinton has announced there is a new national bird?  The spread eagle.\n",
      "\n",
      "Joke ID: 69\n",
      "Score: 14.096344534916815\n",
      "Joke Text: Employer to applicant: \"In this job we need someone who is responsible.\"Applicant: \"I'm the one you want. On my last job every time anything went wrong they said I was responsible.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# the SVD-based version\n",
    "svdEst_pearson_recommend = recommend(\n",
    "    dataMat=jester_data_np, user=441, N=5, simMeas=pearsonSim, estMethod=svdEst\n",
    ")\n",
    "recommendation_output(svdEst_pearson_recommend)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc769673-ddda-4282-892b-5fc9f477f850",
   "metadata": {},
   "source": [
    "_First I imported the necessary libraries along with all the functions from the module itemBasedRec.py. I used load_jokes function to load the jokes dataset. Then used pandas to load the modified_jester_data as dataframe and converted to numpy array as recommend() function takes dataMat as numpy array. I also created a recommendation_output that uses jokes and the output from recommend() function to print joke id, score and joke text as required. for user with id 117, the recommend function with prediction fuction standEst with both cosine and pearson similarity gave similar top recommendations with jokeid 97, 99, 92, 75 appearing on both the lists. However pearson recommended 80 while cosine recommended 88. This is due to Pearson adjusts for each user's rating behaviour and bias, whereas cosine only measures the similarity between rating patterns without accounting for user's bias._\n",
    "\n",
    "_Again for the user with id 441, the recommend function using the standard estimator (standEst) and the SVD-based estimator (svdEst), both with Pearson similarity, returned different sets of jokes, and only the joke with id 5 appeared in both lists. This happens because the standard estimator only relies on direct rating overlap between items, which is limited in a sparse rating matrix where most ratings are 0. On the other hand, the SVD-based estimator reduces the dimensionality of the user-item matrix and represents jokes in a latent feature space, which allows it to infer preferences even when the overlap in ratings is weak or missing (i.e., when many values are 0). As a result, the SVD-based recommendations differ._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2864ca32-ff16-4411-aa41-82184f9a0ac9",
   "metadata": {},
   "source": [
    "### Cross-Validation Evaluation Utility\n",
    "\n",
    "Extend the `test` helper in `itemBasedRec.py` so that it aggregates MAE across users via `cross_validate_user`. With a 20% holdout per user, benchmark the standard estimator against the SVD-based estimator (both using Pearson similarity) to understand how much the latent-factor adjustment improves absolute error.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59f9d386-35b8-4418-9c60-cd8bd236459c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for standEst using Pearson Similarity: 3.6779\n",
      "CPU times: user 23.2 s, sys: 69.7 ms, total: 23.3 s\n",
      "Wall time: 23.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MAE_standEst = test(dataMat=jester_data_df, test_ratio=0.2, estMethod=standEst, simMeas=pearsonSim)\n",
    "print(f'Mean Absolute Error for standEst using Pearson Similarity: {MAE_standEst:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6bc03cf-f13f-4681-9874-5c6173e42a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error for svdEst using Pearson Similarity: 3.6369\n",
      "CPU times: user 15min 44s, sys: 3min 43s, total: 19min 27s\n",
      "Wall time: 7min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MAE_svdEst = test(dataMat=jester_data_df, test_ratio=0.2, estMethod=svdEst, simMeas=pearsonSim)\n",
    "print(f'Mean Absolute Error for svdEst using Pearson Similarity: {MAE_svdEst:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e892b2a1-1c49-4610-9d90-c9f3c07ac7f9",
   "metadata": {},
   "source": [
    "_First I completed the test() function by looping through each user in dataMat which is the length of dataMat(row), then called the cross_validate_user() function to get the user_error and user_count which I sum across all the users to get the MAE on the test data by dividing total_error by total_count. Then I used the 20% test ratio on jester_data_df and calculated for standEst and svdEst estimators on pearsonSim. This gives MAE of 3.6779 for standEst and 3.6369 for svdEst._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b46009e-6dfe-4a39-ac78-5db280e8b489",
   "metadata": {},
   "source": [
    "### Similarity Exploration Helper\n",
    "\n",
    "Implement `print_most_similar_jokes`, a diagnostic utility that surfaces the top-`k` items related to a query joke for any similarity measure. Use it to inspect the three most similar jokes to joke 9 under both Pearson and cosine similarities, highlighting how different similarity definitions change neighborhood composition.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35b47e0a-6d06-49fb-b0fa-41668ed5201d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected joke: Joke # 9\n",
      "Two cannibals are eating a clown one turns to other and says: \"Does this taste funny to you? \n",
      "\n",
      "Top 3 recommendations are : \n",
      "\n",
      "Joke # 54 (Similarity: 0.6930598395934301):\n",
      "A woman has twins and gives them up for adoption.  One of them goes to a family in Egypt and is named \"Amal.\"  The other goes to a  family in Spain; they name him \"Juan.\"  Years later Juan sends a picture of himself to his mom.  Upon receiving the picture she tells her husband that she wishes she also had a picture of Amal.  Her husband responds \"But they are twins-if you've seen Juan you've seen   Amal.\n",
      "\n",
      "Joke # 43 (Similarity: 0.6925114947798079):\n",
      "A horse walks into a bar. Bartender says:\"So why the long face?\"\n",
      "\n",
      "Joke # 37 (Similarity: 0.6881434530285019):\n",
      "\"May I take your order?\" the waiter asked. \"Yes how do you prepare your chickens?\" \"Nothing special sir\" he replied. \"We just tell them straight out that they're going to die.\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_most_similar_jokes(jester_data_df, jokes, 9, 3, pearsonSim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db371a18-5e52-484d-a4d3-07635db5de55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected joke: Joke # 9\n",
      "Two cannibals are eating a clown one turns to other and says: \"Does this taste funny to you? \n",
      "\n",
      "Top 3 recommendations are : \n",
      "\n",
      "Joke # 49 (Similarity: 0.9567814498620507):\n",
      "A guy goes into confession and says to the priest \"Father I'm 80 years old widower with 11 grandchildren. Last night I met two beautiful flight attendants. They took me home and I made love to both of them. Twice.\"The priest said: \"Well my son when was the last time you were in confession?\" \"Never Father I'm Jewish.\" \"So then why are you telling me?\" \"I'm telling everybody.\"\n",
      "\n",
      "Joke # 37 (Similarity: 0.955529834986665):\n",
      "\"May I take your order?\" the waiter asked. \"Yes how do you prepare your chickens?\" \"Nothing special sir\" he replied. \"We just tell them straight out that they're going to die.\"\n",
      "\n",
      "Joke # 87 (Similarity: 0.9554097405075856):\n",
      "A Czechoslovakian man felt his eyesight was growing steadily worse and felt it was time to go see an optometrist. The doctor started with some simple testing and showed him a standard eye chart with letters of diminishing size: CRKBNWXSKZY. . . \"Can you read this?\" the doctor asked. \"Read it?\" the Czech answered. \"Doc I know him!\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_most_similar_jokes(jester_data_np, jokes, 9, 3, cosineSim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7859afd-d45d-4ad2-bbe7-2634c7b3a008",
   "metadata": {},
   "source": [
    "_I implemented the print_most_similar_jokes function, which computes pairwise similarities between a query joke and all other jokes based on user ratings. For joke ID 9, Pearson similarity identified jokes 54, 43, and 37 as most similar, while cosine similarity identified jokes 49, 37, and 87. The difference arises because Pearson correlation centers each rating vector to remove user rating bias, while cosine similarity only normalizes for vector magnitude. As a result, cosine focuses on directional alignment, whereas Pearson captures relative rating patterns._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c1e445-4fc4-4b0a-a7ed-fb1738de88b2",
   "metadata": {},
   "source": [
    "### Model-Based Item Similarity Pipeline\n",
    "\n",
    "To make predictions scalable, pre-compute an item–item similarity matrix once during a training phase and reuse it for estimation. Build reusable helpers for computing similarities with any metric and for generating predictions by weighting a user's ratings on the top-`k` neighbors. Demonstrate the approach by scoring the top two candidate jokes (per the earlier recommendations) for users 117 and 441 using both Pearson- and cosine-derived similarity matrices when `k=10`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9996f33-ab70-49d5-9833-3e212ca4e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(dataMat, metric):\n",
    "    dataMat = np.array(dataMat)\n",
    "    n = np.shape(dataMat)[1]\n",
    "    # initialize an empty n x n matrix to store pairwise similarities between all jokes\n",
    "    simMat = np.zeros((n, n))\n",
    "\n",
    "    # loop through each pair of jokes (i, j) to compute similarity\n",
    "    for i in range(n):\n",
    "        for j in range(i, n):\n",
    "            # find users who rated both jokes i and j (non-zero overlap)\n",
    "            overLap = np.nonzero(np.logical_and(dataMat[:, i] > 0, dataMat[:, j] > 0))[\n",
    "                0\n",
    "            ]\n",
    "            # if overlap exists, compute similarity else assign 0\n",
    "            if len(overLap) == 0:\n",
    "                similarity = 0\n",
    "            else:\n",
    "                # store the computed similarity symmetrically in the matrix\n",
    "                similarity = metric(dataMat[overLap, i], dataMat[overLap, j])\n",
    "            simMat[i, j] = similarity\n",
    "            simMat[j, i] = similarity\n",
    "    # return the complete item–item similarity matrix\n",
    "    return simMat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cad9f8a5-1a75-4c76-81d4-3d106dd57bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_predict(dataMat, simMat, user, item, k):\n",
    "    dataMat = np.array(dataMat)\n",
    "    # get all items (jokes) the user has rated\n",
    "    user_ratings = dataMat[user, :]\n",
    "    # indices of the rated items\n",
    "    rated_items_idx = np.where(user_ratings > 0)[0]\n",
    "\n",
    "    # if user has no ratings return 0\n",
    "    if len(rated_items_idx) == 0:\n",
    "        return 0\n",
    "\n",
    "    # get how similar the item is to all other items (rated items)\n",
    "    item_sims = simMat[item, rated_items_idx]\n",
    "\n",
    "    # sort and get the top k similar items index in reverse\n",
    "    top_k_idx = np.argsort(item_sims)[::-1][:k]\n",
    "    # get the similarity value from index\n",
    "    top_k_sims = item_sims[top_k_idx]\n",
    "    # get the user ratings for these items\n",
    "    top_k_ratings = user_ratings[rated_items_idx[top_k_idx]]\n",
    "\n",
    "    # if sum of the top k similarities is 0 return 0\n",
    "    if np.sum(top_k_sims) == 0:\n",
    "        return 0\n",
    "    # calculate the weighted sum\n",
    "    pred = np.dot(top_k_sims, top_k_ratings) / np.sum(top_k_sims)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "225682b3-dca8-4717-8982-b08b82ecf210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.    0.655 0.671 0.636 0.561 ... 0.577 0.585 0.555 0.612 0.542]\n",
      " [0.655 1.    0.604 0.642 0.563 ... 0.552 0.569 0.604 0.566 0.615]\n",
      " [0.671 0.604 1.    0.685 0.62  ... 0.582 0.557 0.555 0.531 0.603]\n",
      " [0.636 0.642 0.685 1.    0.641 ... 0.639 0.588 0.65  0.573 0.677]\n",
      " [0.561 0.563 0.62  0.641 1.    ... 0.545 0.531 0.594 0.562 0.609]\n",
      " ...\n",
      " [0.577 0.552 0.582 0.639 0.545 ... 1.    0.706 0.657 0.691 0.618]\n",
      " [0.585 0.569 0.557 0.588 0.531 ... 0.706 1.    0.631 0.673 0.556]\n",
      " [0.555 0.604 0.555 0.65  0.594 ... 0.657 0.631 1.    0.634 0.711]\n",
      " [0.612 0.566 0.531 0.573 0.562 ... 0.691 0.673 0.634 1.    0.58 ]\n",
      " [0.542 0.615 0.603 0.677 0.609 ... 0.618 0.556 0.711 0.58  1.   ]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3, edgeitems=5)\n",
    "simMat_pearson = similarity_matrix(jester_data_df, metric=pearsonSim)\n",
    "print(simMat_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7cfe4e9-2cb6-4a78-92df-8bbb514c653b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.    0.943 0.945 0.931 0.925 ... 0.933 0.937 0.924 0.934 0.927]\n",
      " [0.943 1.    0.929 0.928 0.925 ... 0.925 0.93  0.929 0.923 0.934]\n",
      " [0.945 0.929 1.    0.936 0.933 ... 0.928 0.924 0.917 0.914 0.931]\n",
      " [0.931 0.928 0.936 1.    0.929 ... 0.931 0.924 0.929 0.915 0.939]\n",
      " [0.925 0.925 0.933 0.929 1.    ... 0.929 0.927 0.928 0.923 0.935]\n",
      " ...\n",
      " [0.933 0.925 0.928 0.931 0.929 ... 1.    0.957 0.944 0.949 0.942]\n",
      " [0.937 0.93  0.924 0.924 0.927 ... 0.957 1.    0.94  0.947 0.934]\n",
      " [0.924 0.929 0.917 0.929 0.928 ... 0.944 0.94  1.    0.933 0.95 ]\n",
      " [0.934 0.923 0.914 0.915 0.923 ... 0.949 0.947 0.933 1.    0.929]\n",
      " [0.927 0.934 0.931 0.939 0.935 ... 0.942 0.934 0.95  0.929 1.   ]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3, edgeitems=5)\n",
    "simMat_cosine = similarity_matrix(jester_data_df, metric=cosineSim)\n",
    "print(simMat_cosine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5c670c6-e0ef-453f-b520-b2cf62619424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User 117 - Top 2 items with Pearson similarity:\n",
      "Predicted Rating for user: 117 and item: 97 is 10.686\n",
      "Predicted Rating for user: 117 and item: 99 is 11.891\n",
      "\n",
      "User 117 - Top 2 items with Cosine similarity:\n",
      "Predicted Rating for user: 117 and item: 97 is 12.473\n",
      "Predicted Rating for user: 117 and item: 99 is 12.487\n"
     ]
    }
   ],
   "source": [
    "print(\"User 117 - Top 2 items with Pearson similarity:\")\n",
    "for item in [97, 99]:\n",
    "    pred = item_based_predict(jester_data_df, simMat_pearson, 117, item, k=10)\n",
    "    print(f\"Predicted Rating for user: 117 and item: {item} is {pred:.3f}\")\n",
    "\n",
    "print(\"\\nUser 117 - Top 2 items with Cosine similarity:\")\n",
    "for item in [97, 99]:\n",
    "    pred = item_based_predict(jester_data_df, simMat_cosine, 117, item, k=10)\n",
    "    print(f\"Predicted Rating for user: 117 and item: {item} is {pred:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e4cb6bb-66fb-4ed1-bb59-815b61d5f1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "User 441 - Top 2 items with Pearson similarity:\n",
      "Predicted Rating for user: 441 and item: 79 is 15.622\n",
      "Predicted Rating for user: 441 and item: 5 is 15.891\n",
      "\n",
      "User 441 - Top 2 items with Cosine similarity:\n",
      "Predicted Rating for user: 441 and item: 79 is 15.770\n",
      "Predicted Rating for user: 441 and item: 5 is 17.405\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nUser 441 - Top 2 items with Pearson similarity:\")\n",
    "for item in [79, 5]:\n",
    "    pred = item_based_predict(jester_data_df, simMat_pearson, 441, item, k=10)\n",
    "    print(f\"Predicted Rating for user: 441 and item: {item} is {pred:.3f}\")\n",
    "\n",
    "print(\"\\nUser 441 - Top 2 items with Cosine similarity:\")\n",
    "for item in [79, 5]:\n",
    "    pred = item_based_predict(jester_data_df, simMat_cosine, 441, item, k=10)\n",
    "    print(f\"Predicted Rating for user: 441 and item: {item} is {pred:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e682db-bad1-4891-9285-6c855a948800",
   "metadata": {},
   "source": [
    "_I developed item-based collaborative filtering recommender that uses a model-based approach (separating the training and the prediction tasks). The similarity_matrix function precomputes all pairwise item similarities and stores them in a matrix, making predictions much faster than the original implementation. The item_based_predict function uses the precomputed similarity matrix to find the k most similar items that the user has rated, then computes a weighted average of those ratings. This approach is more scalable since similarities are computed once during training rather than for each prediction. Testing on users 117 and 441 showed that the predictions vary between Pearson and cosine similarity measures, with Pearson generally producing more conservative estimates due to its bias adjustment._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b039f3-b866-4e22-a1dd-e533ca169d08",
   "metadata": {},
   "source": [
    "### End-to-End Evaluation and Tuning\n",
    "\n",
    "Augment the cross-validation tooling to support the model-based predictor, then profile performance under both Pearson and cosine similarities. Sweep `k` from 1 to 40 to visualize how neighborhood size affects MAE, select the best-performing `k`, and plug the optimized predictor into the recommendation workflow for users 117 and 441.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d517fc-e3f4-4ae6-84bb-eff2097cac0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate_user2(dataMat, user, test_ratio, simMat, k):\n",
    "    dataMat = np.array(dataMat)\n",
    "    number_of_items = np.shape(dataMat)[1]\n",
    "    # get all items rated by the given user\n",
    "    rated_items_by_user = np.array(\n",
    "        [i for i in range(number_of_items) if dataMat[user, i] > 0]\n",
    "    )\n",
    "    # randomly select test_ratio portion of rated items as test set\n",
    "    test_size = int(test_ratio * len(rated_items_by_user))\n",
    "    test_indices = np.random.randint(0, len(rated_items_by_user), test_size)\n",
    "    withheld_items = rated_items_by_user[test_indices]\n",
    "    # make a copy of original user ratings to restore later\n",
    "    original_user_profile = np.copy(dataMat[user])\n",
    "    # set test items to zero so they are not used in prediction\n",
    "    dataMat[user, withheld_items] = 0\n",
    "    error_u = 0.0\n",
    "    count_u = len(withheld_items)\n",
    "\n",
    "    # compute absolute error for user over all withheld (test) items\n",
    "    for item in withheld_items:\n",
    "        # predict rating for the withheld item using item-based CF\n",
    "        estimatedScore = item_based_predict(dataMat, simMat, user, item, k)\n",
    "        error_u = error_u + abs(estimatedScore - original_user_profile[item])\n",
    "\n",
    "        # restore withheld ratings to the user profile\n",
    "    for item in withheld_items:\n",
    "        dataMat[user, item] = original_user_profile[item]\n",
    "\n",
    "        # return total absolute error and number of test cases for this user\n",
    "        # these will be accumulated across all users to compute overall MAE\n",
    "    return error_u, count_u\n",
    "\n",
    "\n",
    "def test2(dataMat, test_ratio, simMat, k):\n",
    "    total_error = 0.0\n",
    "    total_count = 0\n",
    "\n",
    "    for user in range(len(dataMat)):\n",
    "        user_error, user_count = cross_validate_user2(\n",
    "            dataMat, user, test_ratio, simMat, k\n",
    "        )\n",
    "        total_error += user_error\n",
    "        total_count += user_count\n",
    "\n",
    "    MAE = total_error / total_count\n",
    "    return MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3edb8501-591a-4f5a-9c06-ea6f8a74af35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error using Pearson similarity Matrix: 3.23429509579498\n",
      "CPU times: user 412 ms, sys: 28.7 ms, total: 441 ms\n",
      "Wall time: 443 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MAE = test2(jester_data_df, 0.2, simMat_pearson, 10)\n",
    "print(f'Mean Absolute Error using Pearson similarity Matrix: {MAE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c8729e19-76dc-4536-9e8b-db7d5da1fbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error using Cosine similarity Matrix: 3.480072283376019\n",
      "CPU times: user 397 ms, sys: 23.4 ms, total: 420 ms\n",
      "Wall time: 421 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MAE = test2(jester_data_df, 0.2, simMat_cosine, 10)\n",
    "print(f'Mean Absolute Error using Cosine similarity Matrix: {MAE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "403fe156-2308-42b0-a4df-773409d9d6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, mae=3.846466121917713\n",
      "k=2, mae=3.483420443340615\n",
      "k=3, mae=3.376153511204002\n",
      "k=4, mae=3.293383750130299\n",
      "k=5, mae=3.245611717927619\n",
      "k=6, mae=3.2546110791402323\n",
      "k=7, mae=3.2221224811448637\n",
      "k=8, mae=3.2675076302491988\n",
      "k=9, mae=3.197719276443022\n",
      "k=10, mae=3.2181296948522817\n",
      "k=11, mae=3.227795547096072\n",
      "k=12, mae=3.2452350899352487\n",
      "k=13, mae=3.184864894788684\n",
      "k=14, mae=3.2547963243393574\n",
      "k=15, mae=3.247410109681899\n",
      "k=16, mae=3.2600908874557013\n",
      "k=17, mae=3.2687529244142945\n",
      "k=18, mae=3.266699440546572\n",
      "k=19, mae=3.2977697667309163\n",
      "k=20, mae=3.292550308609975\n",
      "k=21, mae=3.291646530677592\n",
      "k=22, mae=3.3111402394331697\n",
      "k=23, mae=3.35215278521342\n",
      "k=24, mae=3.350053005340751\n",
      "k=25, mae=3.3219984412847396\n",
      "k=26, mae=3.369356047902486\n",
      "k=27, mae=3.4034392458320455\n",
      "k=28, mae=3.4016319280579808\n",
      "k=29, mae=3.3932331089339565\n",
      "k=30, mae=3.3210657302027466\n",
      "k=31, mae=3.385352158371818\n",
      "k=32, mae=3.4289749645708274\n",
      "k=33, mae=3.4060126023899935\n",
      "k=34, mae=3.4091172866890327\n",
      "k=35, mae=3.4261613939914977\n",
      "k=36, mae=3.4558186204975567\n",
      "k=37, mae=3.412699695055255\n",
      "k=38, mae=3.4650232225240103\n",
      "k=39, mae=3.479232093757264\n",
      "k=40, mae=3.4457675936321523\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute MAE for range of k values\n",
    "k_range = np.arange(1, 41)\n",
    "kvals = []\n",
    "mae_score = []\n",
    "\n",
    "for k in k_range:\n",
    "    mae = test2(jester_data_df, 0.2, simMat_pearson, k)\n",
    "    print('k={}, mae={}'.format(k, mae))\n",
    "    kvals.append(k)\n",
    "    mae_score.append(mae)\n",
    "\n",
    "# plot results\n",
    "%matplotlib inline\n",
    "plt.plot(kvals, mae_score, '-o')\n",
    "plt.xlabel('K value')\n",
    "plt.ylabel('MAE')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e4356-942b-4c73-8ca8-9653c4e3b44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_based_recommend(dataMat, simMat, user, k, N=3):\n",
    "    # find all unrated items (ratings equal to 0) for the given user\n",
    "    unratedItems = np.nonzero(dataMat[user, :] == 0)[0]\n",
    "\n",
    "    # if the user has rated all items, return message\n",
    "    if len(unratedItems) == 0:\n",
    "        return \"you rated everything\"\n",
    "    itemScores = []\n",
    "    # loop through each unrated item to predict its rating\n",
    "    for item in unratedItems:\n",
    "        # predict rating using item-based collaborative filtering\n",
    "        estimatedScore = item_based_predict(dataMat, simMat, user, item, k)\n",
    "        # store item id and its predicted score as a tuple\n",
    "        itemScores.append((item, estimatedScore))\n",
    "    # sort items in decreasing order of predicted rating and return top N\n",
    "    return sorted(itemScores, key=lambda jj: jj[1], reverse=True)[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa242ba-e436-4faf-9556-5265a29ded47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best k: 13\n",
      "Top 3 Recommended jokes for user 117:\n",
      "\n",
      "Joke # 92, predicted rating: 11.668781449568131\n",
      "Reaching the end of a job interview the human resources person asked a young engineer fresh out of Stanford\"And what starting salary were you looking for?\"The engineer said \"In the neighborhood of $125000 a year depending on the benefits package.\"The interviewer said \"Well what would you say to a package of 5-weeks vacation 14 paid holidays full medical and dental company matching retirement fund to 50% of salary and a company car leased every 2 years - say a red Corvette?\"The Engineer sat up straight and said \"Wow! Are you kidding?\"And the interviewer replied \"Yeah but you started it.\" \n",
      "\n",
      "Joke # 90, predicted rating: 11.492723747918491\n",
      "A Panda bear walks into a bar.  Sits down at a table and orders a beer and a double cheeseburger.  After he is finished eating he pulls out a gun and rips the place with gunfire.  Patrons scatter and dive under chairs and tables as the bear runs out the door.  After ensuring that no one is hurt the bartender races out the door and calls after the bear \"What the hell did you do that for?\"  The bear calls back \"I'm a Panda bear.  Look it up in the dictionary.\"  The bartender returns pulls out his dictionary.panda : \\Pan\"da\\ n. (Zo[\"o]l.)A small Asiatic mammal (Ailurus fulgens) having fine soft fur.It is related to the bears and inhabits the mountains of Northern India.Eats shoots and leaves. \n",
      "\n",
      "Joke # 93, predicted rating: 11.239832169297083\n",
      "Two atoms are walking down the street when one atom says to the other \"Oh my! I've lost an electron!\"The second atom says\"Are you sure\"The first replies \"I'm positive!\" \n",
      "\n",
      "=========================================\n",
      "Top 3 Recommended jokes for user 441:\n",
      "\n",
      "Joke # 99, predicted rating: 16.604841687229996\n",
      "Q: What's the difference between greeting a Queen and greeting thePresident of the United  States?A: You only have to get on one knee to greet the queen. \n",
      "\n",
      "Joke # 75, predicted rating: 16.46433083739234\n",
      "There once was a man and a woman that both  got in  a terrible car wreck. Both of their vehicles  were completely destroyed buy fortunately no one  was   hurt.  In thankfulness the woman said to the man 'We are both okay so we should celebrate. I have   a  bottle of wine in my car let's open it.' So the woman got the bottle out of the car and  handed it to the man. The man took a really big drink and handed the woman the bottle. The  woman  closed the bottle and put it down. The man  asked  'Aren't you going to take a drink?' The woman cleverly replied 'No I think I'll  just  wait for the cops to get here.' \n",
      "\n",
      "Joke # 71, predicted rating: 16.440424598859984\n",
      "On the first day of college the Dean addressed the students pointing out some of the rules:\"The female dormitory will be out-of-bounds for all male students and the male dormitory to the female students. Anybody caught breaking this rule will be fined $20 the first time.\" He continued \"Anybody caught breaking this rule the second time will be fined $60. Being caught a third time will cost you a fine of $180. Are there any questions ?\"At this point a male student in the crowd inquired:\"How much for a season pass ?\" \n",
      "\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "# find best k and generate recommendations\n",
    "best_k = kvals[np.argmin(mae_score)]\n",
    "print(f\"\\nBest k: {best_k}\")\n",
    "\n",
    "# Generate recommendations\n",
    "N = 3\n",
    "user_index = [117, 441]\n",
    "\n",
    "for user in user_index:\n",
    "    recommendations = item_based_recommend(\n",
    "        jester_data_np, simMat_pearson, user, best_k, N\n",
    "    )\n",
    "    print(\"Top {} Recommended jokes for user {}:\\n\".format(N, user))\n",
    "    for r in recommendations:\n",
    "        print(\"Joke # {}, predicted rating: {}\".format(r[0], r[1]))\n",
    "        print(get_joke_text(jokes, r[0]), \"\\n\")\n",
    "    print(\"=========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bf9eb2-0bef-4d23-930b-028d6abba6bd",
   "metadata": {},
   "source": [
    "_I modified the cross_validate_user and test functions to work with the new item-based prediction function by creating cross_validate_user2 and test2 functions that accept a similarity matrix and k parameter. I tested the prediction accuracy using both Pearson and cosine similarity measures with k=10, which showed comparable performance to the original methods. Next, I computed MAE values across a range of k values from 1 to 40 to find the optimal k. The plot shows how prediction accuracy varies with k, where smaller k values may miss important similar items while larger k values may include less relevant items, affecting the weighted average. I identified the best k value that minimizes MAE from the plot. Finally, I modified the recommend function to create item_based_recommend that uses the item_based_predict function and generated top 3 recommendations for users 117 and 441 using the optimal k value. The results demonstrate that the model-based approach with precomputed similarities provides an efficient and scalable alternative to the original implementation._\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
